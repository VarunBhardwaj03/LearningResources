{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_TensorBasics.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOS2KAqj48z8tCJ1VPchZhU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"v9GplRrgvGGP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600173092364,"user_tz":-330,"elapsed":6546,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}}},"source":["import torch"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"vt_AcCfyv1C-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600173498213,"user_tz":-330,"elapsed":1402,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"e64377c9-3cd6-4944-9ab7-e1c1fae1030d"},"source":["# Everything in pytorch is based on Tensor operations.\n","# A tensor can have different dimensions\n","# so it can be 1d, 2d, or even 3d and higher\n","\n","# scalar, vector, matrix, tensor\n","\n","# torch.empty(size): uninitiallized\n","x = torch.empty(3)\n","print(x)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tensor([1.8137e-35, 0.0000e+00, 3.3631e-44])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KRl1HBE1xdiV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":782},"executionInfo":{"status":"ok","timestamp":1600173555580,"user_tz":-330,"elapsed":1132,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"4058f6d8-b03b-48ef-c7e9-ba1c5e05879b"},"source":["x = torch.empty(2,3)\n","print(x)\n","x = torch.empty(3,2,3)\n","print(x)\n","x = torch.empty(1)\n","print(x)\n","x = torch.empty(4,2,3,5)\n","print(x)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["tensor([[1.8137e-35, 0.0000e+00, 1.6816e-43],\n","        [0.0000e+00, 1.4013e-45, 0.0000e+00]])\n","tensor([[[1.8021e-35, 0.0000e+00, 7.0065e-44],\n","         [6.7262e-44, 6.3058e-44, 6.7262e-44]],\n","\n","        [[7.9874e-44, 6.3058e-44, 6.8664e-44],\n","         [7.4269e-44, 1.1771e-43, 6.8664e-44]],\n","\n","        [[7.0065e-44, 8.1275e-44, 7.1466e-44],\n","         [7.9874e-44, 8.1275e-44, 6.8664e-44]]])\n","tensor([1.8137e-35])\n","tensor([[[[1.4461e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","\n","         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n","\n","\n","        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","\n","         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n","\n","\n","        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","\n","         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]],\n","\n","\n","        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]],\n","\n","         [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n","          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1F2nNJfvxpfy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600173598955,"user_tz":-330,"elapsed":693,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"a63f0635-3029-4902-cb2a-574e1b0a69de"},"source":["# torch.rand(size): produces a matrix of shape = size and random numbers in [0, 1] \n","x = torch.rand([2,2])\n","print(x)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["tensor([[0.2193, 0.0516],\n","        [0.9557, 0.3550]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H9koxoYix0lr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600173707599,"user_tz":-330,"elapsed":1077,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"2596b803-2881-4cda-c949-383588231ca3"},"source":["# torch.zeros(size), fill with 0\n","# torch.ones(size), fill with 1\\\n","x = torch.zeros(2,2)\n","print(x)\n","x = torch.ones(2,2)\n","print(x)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([[0., 0.],\n","        [0., 0.]])\n","tensor([[1., 1.],\n","        [1., 1.]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xo8o6jqtyQyw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600173783789,"user_tz":-330,"elapsed":1023,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"71344026-25ec-49d9-be46-b829ef9a36d1"},"source":["#check size\n","print(x.size())\n","#check data type\n","print(x.dtype)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["torch.Size([2, 2])\n","torch.float32\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d9EAFZO7yjZl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600173871643,"user_tz":-330,"elapsed":1078,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}}},"source":["#float32 is a 32 bit number - float64 uses 64 bits. That means that float64's take up twice as much memory - \n","#and doing operations on them may be a lot slower in some machine architectures. \n","#However, float64's can represent numbers much more accurately than 32 bit floats. \n","#They also allow much larger numbers to be stored."],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jyx2Gv7Uy41u","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600174005427,"user_tz":-330,"elapsed":1126,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"4058e8ee-3b4d-49ce-8257-252fa454a5db"},"source":["# specify types, float32 default\n","x = torch.zeros(3,3 , dtype=torch.float16)\n","print(x)\n","print(x.dtype)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]], dtype=torch.float16)\n","torch.float16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DosKpn-YzQoc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1600174172182,"user_tz":-330,"elapsed":1303,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"1cbef43f-3a33-41ea-a13c-923ae5537948"},"source":["# requires_grad argument\n","# This will tell pytorch that it will need to calculate the gradients for this tensor\n","# later in your optimization steps\n","# i.e. this is a variable in your model that you want to optimize\n","x = torch.tensor([5.5,3],requires_grad=True)\n","print(x)\n","print(x.dtype)\n","print(x.size())"],"execution_count":15,"outputs":[{"output_type":"stream","text":["tensor([5.5000, 3.0000], requires_grad=True)\n","torch.float32\n","torch.Size([2])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5ieR_aJfzn7j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600174346959,"user_tz":-330,"elapsed":1464,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"0bcc85e5-bae2-4f80-e48f-9616f2ab6a17"},"source":["\n","# Operations\n","y = torch.rand(2, 2)\n","x = torch.rand(2, 2)\n","\n","# elementwise addition\n","z = x + y\n","print(z)\n","print(torch.add(x,y))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["tensor([[1.4523, 1.1783],\n","        [0.5146, 1.7595]])\n","tensor([[1.4523, 1.1783],\n","        [0.5146, 1.7595]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3Hmbxo2D0m92","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1600174408946,"user_tz":-330,"elapsed":1163,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"c7d749c2-b055-4f77-9c19-1db94446d92b"},"source":["# in place addition, everythin with a trailing underscore is an inplace operation\n","# i.e. it will modify the variable\n","print(y)\n","print(y.add_(x)) #this will modify y\n","print(y)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["tensor([[1.4523, 1.1783],\n","        [0.5146, 1.7595]])\n","tensor([[2.0992, 1.8570],\n","        [0.8260, 2.6559]])\n","tensor([[2.0992, 1.8570],\n","        [0.8260, 2.6559]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EjI22LNl0zdc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600174504285,"user_tz":-330,"elapsed":1244,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"fddea3de-9359-4251-ba71-aa378c66a231"},"source":["# substraction\n","z = x - y\n","print(z)\n","z = torch.sub(x, y)\n","print(z)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["tensor([[-1.4523, -1.1783],\n","        [-0.5146, -1.7595]])\n","tensor([[-1.4523, -1.1783],\n","        [-0.5146, -1.7595]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wfPVhn5I1UZJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600174517396,"user_tz":-330,"elapsed":1354,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"50914a60-67b8-4769-d0cb-d73224b3f9a4"},"source":["# multiplication\n","z = x * y  ##elementwise multiplication\n","print(z)\n","z = torch.mul(x,y) #elementwise multiplication\n","print(z)\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["tensor([[1.3581, 1.2604],\n","        [0.2572, 2.3809]])\n","tensor([[1.3581, 1.2604],\n","        [0.2572, 2.3809]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"and4GE_k1W8G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600174524945,"user_tz":-330,"elapsed":1187,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"18c21191-57c9-42d1-b5f9-55429dc2720f"},"source":["# division\n","z = x / y\n","print(z)\n","z = torch.div(x,y)\n","print(z)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["tensor([[0.3082, 0.3655],\n","        [0.3770, 0.3375]])\n","tensor([[0.3082, 0.3655],\n","        [0.3770, 0.3375]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gNkOGcvA1F7Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1600174756539,"user_tz":-330,"elapsed":1156,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"b46f4e9b-ac6b-4413-cf77-d9cc2edd11cf"},"source":["# Slicing\n","x = torch.rand(5,3)\n","print(x)\n","print(x[:, 0]) # all rows, column 0\n","print(x[1, :]) # row 1, all columns\n","print(x[1,1]) # element at 1, 1"],"execution_count":26,"outputs":[{"output_type":"stream","text":["tensor([[0.9753, 0.1030, 0.6485],\n","        [0.5231, 0.7702, 0.3907],\n","        [0.1367, 0.2159, 0.0690],\n","        [0.2480, 0.8557, 0.6118],\n","        [0.1488, 0.0049, 0.1751]])\n","tensor([0.9753, 0.5231, 0.1367, 0.2480, 0.1488])\n","tensor([0.5231, 0.7702, 0.3907])\n","tensor(0.7702)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"osCbshvr1N9s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600174863518,"user_tz":-330,"elapsed":1194,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"f46d36dc-d091-4810-9602-bf646ad8946b"},"source":["# Get the actual value if only 1 element in your tensor\n","#only one element tensors can be converted to Python scalars\n","print(x[1,1].item())"],"execution_count":31,"outputs":[{"output_type":"stream","text":["0.7702391147613525\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i4kPhCDo2jL-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600175012525,"user_tz":-330,"elapsed":1652,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"47739bdb-ff9f-4ca7-a79a-790e3f186d6c"},"source":["# Reshape with torch.view()\n","x = torch.randn(4, 4)\n","y = x.view(16)\n","# the size -1 is inferred from other dimensions\n","# if -1 pytorch will automatically determine the necessary size\n","z = x.view(-1, 8)\n","w = x.view(1,-1,8)\n","print(x.size(), y.size(), z.size(),w.size())"],"execution_count":36,"outputs":[{"output_type":"stream","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) torch.Size([1, 2, 8])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OWtJsyuZ2xxQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1600175401353,"user_tz":-330,"elapsed":1103,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"64089a35-db82-4efb-fc30-cdb3853dc300"},"source":["# Numpy\n","import numpy as np\n","# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n","a = torch.ones(5)\n","print(a)\n","print(type(a))\n","\n","# torch to numpy with .numpy()\n","b = a.numpy()\n","print(b)\n","print(type(b))\n","\n","# Carful: If the Tensor is on the CPU (not the GPU),\n","# both objects will share the same memory location, so changing one\n","# will also change the other\n","a.add_(1)\n","print(a)\n","print(b)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["tensor([1., 1., 1., 1., 1.])\n","<class 'torch.Tensor'>\n","[1. 1. 1. 1. 1.]\n","<class 'numpy.ndarray'>\n","tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gG5c4PEt3fD8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1600175348367,"user_tz":-330,"elapsed":1586,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}},"outputId":"e7c90e3b-b9cd-4fea-cfa7-e66c627443f1"},"source":["# numpy to torch with .from_numpy(x)\n","import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","print(\"a = {}\".format(a))\n","print(type(a))\n","print(\"b = {}\".format(b))\n","print(type(b))\n","# again be careful when modifying\n","a += 1\n","print(a)\n","print(b)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["a = [1. 1. 1. 1. 1.]\n","<class 'numpy.ndarray'>\n","b = tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n","<class 'torch.Tensor'>\n","[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jUX1OaUX4n4l","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600175655272,"user_tz":-330,"elapsed":1207,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}}},"source":["# by default all tensors are created on the CPU,\n","# but you can also move them to the GPU (only if it's available )\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    z = x + y\n","    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n","    # move to CPU again\n","    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n","    # z = z.numpy()"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ab0vEt_M5f3W","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600175656463,"user_tz":-330,"elapsed":876,"user":{"displayName":"Aayush Sharma","photoUrl":"","userId":"06110750062533504361"}}},"source":["if torch.cuda.is_available():\n","  print(\"Yes Gpu is available\")"],"execution_count":64,"outputs":[]}]}
